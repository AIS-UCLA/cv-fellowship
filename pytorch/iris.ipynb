{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Iris* flower classification with PyTorch\n",
    "In this notebook, you will reimplement your 2-layer (4-16-3) fully connected\n",
    "network from the first project. We will skip some of the steps for the sake of\n",
    "brevity, this is just to get you familiar with the PyTorch environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cpu\") # Put your device string here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first setup our dataset as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define our new PyTorch model! In Torch, models are defined as\n",
    "classes that extend `nn.Module`, similar to how we defined our MLP in micrograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class IrisNet(nn.Module):\n",
    "  # First, we must define our constructor.\n",
    "  def __init__(self):\n",
    "    super(IrisNet, self).__init__()\n",
    "    # TODO: Define our layers here (4, 16, 3)\n",
    "    self.layer1 = ...\n",
    "    self.layer2 = ...\n",
    "    self.layer3 = ...\n",
    "  \n",
    "  # Now we need to instruct how to compute the forward pass.\n",
    "  def forward(self, x):\n",
    "    # The first layer is done for you as an example:\n",
    "    x = F.relu(self.layer1(x))\n",
    "    # TODO: Complete the next two layers.\n",
    "    x = ...\n",
    "    x = ... # Remember that the final layer is linear.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is defined, we can instantiate it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisNet().to(DEVICE) # The to() method allows us to do calculations on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's try evaluating our model on the first flower in the training set.\n",
    "We don't need to implement our own softmax function this time, as it is built-in\n",
    "to PyTorch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(model(train_x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we need to train the model. But torch makes this easy with built-in\n",
    "optimizers and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01) # In practice, we can use other optimizers, such as Adam.\n",
    "\n",
    "for epoch in range(1000):\n",
    "  # forward\n",
    "  scores = model(train_x) # Note we can just pass the whole dataset at once!\n",
    "  loss = loss_fn(scores, train_y)\n",
    "\n",
    "  # backward\n",
    "  optimizer.zero_grad() # Zero out the gradients.\n",
    "  loss.backward() # Compute the gradients.\n",
    "  optimizer.step() # Update the parameters automatically!\n",
    "\n",
    "  if epoch % 100 == 0:\n",
    "    print(f\"Epoch {epoch} | Accuracy: {torch.sum(torch.argmax(scores, dim=1) == train_y).item() / len(train_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final accuracy:\", torch.sum(torch.argmax(model(test_x), dim=1) == test_y).item() / len(test_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv-fellowship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
